{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on this project: https://www.blog.datahut.co/post/scraping-amazon-best-seller-data-using-python\n",
    "\n",
    "# Importing libraries\n",
    "import time\n",
    "import random\n",
    "import csv  \n",
    "from csv import writer\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import undetected_chromedriver as uc #driver that can't be detected by websites as a scraper\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to delay some process\n",
    "def delay():\n",
    "    # time.sleep(random.randint(1, 3))\n",
    "    time.sleep(1)\n",
    "\n",
    "# Scrolling down the page in order to overcome Lazy Loading\n",
    "def lazy_loading(n):\n",
    "    element = driver.find_element(By.TAG_NAME, 'body')\n",
    "    count = 0\n",
    "    while count < n:\n",
    "        element.send_keys(Keys.PAGE_DOWN)\n",
    "        delay()\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mercado libre scraping, just test\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(r\"--user-data-dir=C:\\Users\\j50022283\\AppData\\Local\\Google\\Chrome\\User Data\\Default\") #change this to your profile path, you can get it on google in this link: 'chrome://version/'\n",
    "\n",
    "driver = uc.Chrome(options=options)\n",
    "# driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "url = \"https://www.mercadolibre.com.mx/la-teoria-del-todo-el-origen-y-el-destino-del-universo-de-hawking-stephen-serie-ensayo-editorial-debolsillo-tapa-blanda-en-espanol-2010/p/MLM21056700?matt_tool=52069260&matt_word=&matt_source=google&matt_campaign_id=19652628393&matt_ad_group_id=143232870702&matt_match_type=&matt_network=g&matt_device=c&matt_creative=647515868841&matt_keyword=&matt_ad_position=&matt_ad_type=pla&matt_merchant_id=735123861&matt_product_id=MLM21056700-product&matt_product_partition_id=1816346066369&matt_target_id=aud-2038635960613:pla-1816346066369&gclid=Cj0KCQjw3JanBhCPARIsAJpXTx7q0j-A5J3lxRuaf0fsXJ9OT-9Ad5ROffJw-PuvEWkyRwLVxCumYokaArI9EALw_wcB\"\n",
    "\n",
    "driver.get(url)\n",
    "page_content = driver.page_source\n",
    "soup = BeautifulSoup(page_content, 'html.parser')\n",
    "print(\"\\n\" + \"The following URL is being scraped out: \", url)\n",
    "\n",
    "# getting name\n",
    "try:\n",
    "    name_of_product = soup.find('h1', attrs={\"class\": \"ui-pdp-title\"}).text.strip()\n",
    "except:\n",
    "    name_of_product = 'Product name not available '\n",
    "print(name_of_product)\n",
    "\n",
    "# getting features\n",
    "try:\n",
    "    features = soup.find('table', attrs={\"class\": \"andes-table\"})\n",
    "    features = features.find_all('span', attrs={\"class\": \"andes-table__column--value\"})\n",
    "except:\n",
    "    features = 'features not available '\n",
    "print(features)\n",
    "\n",
    "# getting description\n",
    "try:\n",
    "    description = soup.find('p', attrs={\"class\": \"ui-pdp-description__content\"}).text.strip()\n",
    "except:\n",
    "    description = 'desc not available '\n",
    "print(description)\n",
    "\n",
    "\n",
    "lazy_loading(6)\n",
    "\n",
    "button_show_opinions = driver.find_element(by=By.CLASS_NAME, value=\"show-more-click\")\n",
    "button_show_opinions.click()\n",
    "\n",
    "time.sleep(5)\n",
    "element_inside_popup = driver.find_element(by=By.CLASS_NAME, value=\"infinite-scroll-component \")\n",
    "element_inside_popup.send_keys(Keys.PAGE_DOWN)\n",
    "element_inside_popup.send_keys(Keys.PAGE_DOWN)\n",
    "element_inside_popup.send_keys(Keys.END)\n",
    "\n",
    "# lazy_loading(5)\n",
    "\n",
    "page_content = driver.page_source\n",
    "soup = BeautifulSoup(page_content, 'html.parser')\n",
    "print(\"scraping opinions out: \")\n",
    "\n",
    "# getting opinions\n",
    "try:\n",
    "    opinions = soup.find_all('p', attrs={\"class\": \"ui-review-capability-comments__comment__content\"})\n",
    "except:\n",
    "    opinions = 'Product name not available '\n",
    "print(opinions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
